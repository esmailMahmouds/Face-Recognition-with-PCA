{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        num_cols = int(data[3:5])\n",
    "        num_rows = int(data[6:9])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=14)\n",
    "        return np.array(parsed).reshape(num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visaulize 8th individual\n",
    "id = 8\n",
    "plt.figure(figsize=(8,8))\n",
    "for j in range(1,11):\n",
    "    img = read_image_file(f\"faces/s{id}/{j}.pgm\")\n",
    "    plt.subplot(4, 5, j)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visaulize 1st image of all individuals \n",
    "plt.figure(figsize=(40,40))\n",
    "for id in range(1,41):\n",
    "    img = read_image_file(f\"faces/s{id}/{1}.pgm\")\n",
    "    plt.subplot(10,10,id)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-40 individuals, 10 images each, each image is 112x92\n",
    "\n",
    "# Data Matrix\n",
    "D = np.empty((0, 112*92), dtype=float) # number of images [rows] x number of pixels [columns]\n",
    "# label vector\n",
    "y = np.array([], dtype=int)\n",
    "\n",
    "for id in range(1, 41):\n",
    "    for j in range(1, 11):\n",
    "        img = read_image_file(f\"faces/s{id}/{j}.pgm\")\n",
    "        D = np.vstack((D, img.reshape(1, -1).astype(float)))\n",
    "        y = np.append(y,id)\n",
    "\n",
    "# shape of Data Matrix and label vector\n",
    "print(D.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into training and testing sets\n",
    "odd_rows = np.array([i % 2 != 0 for i in range(400)]) \n",
    "\n",
    "# odds rows for taining set\n",
    "D_train = D[odd_rows]\n",
    "y_train = y[odd_rows]\n",
    "\n",
    "# even rows for testing set\n",
    "D_test = D[~ odd_rows]\n",
    "y_test = y[~ odd_rows]\n",
    "\n",
    "# shapes of resulting dataset\n",
    "print(D_train.shape, y_train.shape)\n",
    "print(D_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA():\n",
    "    def __init__(self, Data, eigen_values=None, eigen_vectors=None):\n",
    "        \"\"\"\n",
    "        Initialize PCA with data and optional eigenvalues and eigenvectors.\n",
    "        :param Data: The data matrix.\n",
    "        :param eigen_values: Optional eigenvalues.\n",
    "        :param eigen_vectors: Optional eigenvectors.\n",
    "        \"\"\"\n",
    "        self.CenteredData = Data - np.mean(Data, axis=0)\n",
    "        \n",
    "        if eigen_values is not None and eigen_vectors is not None:\n",
    "            self.eigen_values = eigen_values\n",
    "            self.eigen_vectors = eigen_vectors\n",
    "        else:\n",
    "            self.calc_eig()\n",
    "\n",
    "    def project(self, alpha=0.85):\n",
    "        \"\"\"\n",
    "        Project the data into the PCA space.\n",
    "        :param alpha: The percentage of variance to be explained.\n",
    "        :return: The projected data.\n",
    "        \"\"\"\n",
    "        # check if alpha is between 0 and 1\n",
    "        if alpha < 0 or alpha > 1:\n",
    "            raise ValueError(\"alpha must be between 0 and 1\")\n",
    "\n",
    "        # count PCs from aplha\n",
    "        num_components = self.count_num_components(alpha)\n",
    "\n",
    "        # get projection matrix with num_components\n",
    "        projection_mat = self.eigen_vectors[:,:num_components]\n",
    "\n",
    "        # compute projected data\n",
    "        return self.CenteredData @ projection_mat\n",
    "    \n",
    "    def calc_eig(self):\n",
    "        \"\"\"\n",
    "        Calculate the eigenvalues and eigenvectors of the covariance matrix.\n",
    "        :return: The sorted eigenvalues and eigenvectors.\n",
    "        \"\"\"\n",
    "        # covariance matrix\n",
    "        cov_mat = np.cov(self.CenteredData, rowvar=False)\n",
    "\n",
    "        # eigenvalues and eigenvectors\n",
    "        self.eigen_values, self.eigen_vectors = np.linalg.eigh(cov_mat) \n",
    "\n",
    "        # sort indices\n",
    "        sort_idx = np.argsort(self.eigen_values)[::-1]\n",
    "        self.eigen_values  = self.eigen_values[sort_idx]\n",
    "        self.eigen_vectors = self.eigen_vectors[:, sort_idx]\n",
    "\n",
    "    def count_num_components(self, alpha):\n",
    "        \"\"\"\n",
    "        Count the number of components needed to explain a certain percentage of variance.\n",
    "        :param alpha: The percentage of variance to be explained.\n",
    "        :return: The number of components needed.\n",
    "        \"\"\"\n",
    "        total_var = np.sum(self.eigen_values)\n",
    "        cumvar = np.cumsum(self.eigen_values) / total_var\n",
    "\n",
    "        num_components = np.searchsorted(cumvar, alpha) + 1\n",
    "        return num_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize PCA with no loaded eigenvalues and eigenvectors\n",
    "pca_first = PCA(D_train)\n",
    "# eigens\n",
    "eigen_values, eigen_vectors = pca_first.eigen_values, pca_first.eigen_vectors\n",
    "\n",
    "# save eigen values and vectors\n",
    "np.save(\"eigen_values.npy\", eigen_values)\n",
    "np.save(\"eigen_vectors.npy\", eigen_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eigen values and vectors\n",
    "eigen_values = np.load(\"eigen_values.npy\")\n",
    "eigen_vectors = np.load(\"eigen_vectors.npy\")\n",
    "\n",
    "# initialize PCA with loaded eigen values and vectors\n",
    "pca = PCA(D_train, eigen_values, eigen_vectors)\n",
    "\n",
    "# check dimensions of eigen values and vectors\n",
    "print(eigen_values.shape, eigen_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with different aplhas\n",
    "alphas = [.8, .85, .9, .95]\n",
    "# D_projections {alpha: projected_data} \n",
    "D_projections = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    D_projections[alpha] = pca.project(alpha)\n",
    "    print(f\"Dimensions at alpha= {alpha} : {D_projections[alpha].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct images of some samples with different number of components\n",
    "sample_faces = [0, 5]\n",
    "num_components = [10, 50, 100, 150, 200]\n",
    "reconstruct_images = {}\n",
    "j = 0\n",
    "for  k in sample_faces:\n",
    "    for i in num_components:\n",
    "        img = D_train[k] @ (eigen_vectors[:,:i] @ eigen_vectors[:,:i].T) + np.mean(D_train, axis=0)\n",
    "        reconstruct_images[(k,i)] = img\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visaulize reconstucted faces in PCA space\n",
    "plt.figure(figsize=(10,10))\n",
    "j = 1\n",
    "for key, img in reconstruct_images.items():\n",
    "        plt.subplot(5,5,j)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"sample face {key[0]+1}\\n{key[1]} components\",fontsize=10)\n",
    "        plt.imshow(img.reshape(112,92), cmap='gray')\n",
    "        j = j + 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Eigenfaces with tup 10 eigen values\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(10):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(eigen_vectors[:, i].reshape(112, 92), cmap='gray')\n",
    "    plt.title(f\"Eigenface {i + 1} ({eigen_values[i]:.2f})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "class KMeans():\n",
    "    def __init__(self, K, rand_start=20):\n",
    "        self.K = K\n",
    "        self.rand_start = rand_start\n",
    "    \n",
    "    def setK(self, K):\n",
    "        self.K = K\n",
    "\n",
    "    def fit(self, D, y):\n",
    "        r_best = np.array([])\n",
    "        min_inertia = np.inf\n",
    "\n",
    "        # apply kmeans (rand_start) times\n",
    "        for i in range(self.rand_start):\n",
    "            # set K random centeriods: centers (K, # features)\n",
    "            centers = np.random.rand(self.K, D.shape[1]) * np.random.randint(np.max(D))\n",
    "\n",
    "            # intialize responsibility matrix(1-hot encode) with zeroes: r (# samples, k)\n",
    "            r = np.zeros((D.shape[0], self.K), dtype=bool)\n",
    "            \n",
    "            r, centers = self.kmeans_loop(D, r, centers)\n",
    "\n",
    "            # evaluate best cluster using interia\n",
    "            err = self.inertia(D, r, centers)\n",
    "            if  err < min_inertia:\n",
    "                r_best = r\n",
    "                min_inertia = err\n",
    "        \n",
    "        return r_best\n",
    "        \n",
    "    def kmeans_loop(self, D, r, centers):\n",
    "        r_prev = r.copy()\n",
    "\n",
    "        while True:\n",
    "            # compute Distance matrix for each data point x=D[i] with each center\n",
    "            # assign cluster for each data point\n",
    "            for i in range(len(D)):\n",
    "                cluster = np.argmin(np.linalg.norm(centers - D[i], axis=1))\n",
    "                r[i] = [j == cluster for j in range(self.K)]\n",
    "\n",
    "            # test for convergence\n",
    "            if np.array_equal(r_prev, r):\n",
    "                break\n",
    "            else:\n",
    "                r_prev = r.copy()\n",
    "            \n",
    "            # refitting center of each cluster\n",
    "            for j in range(self.K):\n",
    "                centers[j] = np.mean(D[r[:,j]], axis=0)\n",
    "        \n",
    "        return r, centers\n",
    "    \n",
    "    def inertia(self, D, r, centers):\n",
    "        # sum of Euclidean dist from each point to its cluster\n",
    "        sum = 0\n",
    "        for j in range(self.K):\n",
    "            cluster_dis = np.linalg.norm(D[r[:,j]] - centers[j], axis=1)\n",
    "            sum = sum + np.sum(cluster_dis)\n",
    "\n",
    "        return sum\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max and min values in each D_projection\n",
    "range_values = {}\n",
    "for alpha in alphas:\n",
    "    range_values[alpha] = (np.min(D_projections[alpha]), np.max(D_projections[alpha]))\n",
    "    print(f\"Range of values at alpha= {alpha} : {range_values[alpha]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the projections\n",
    "D_projections_standardized = {}\n",
    "for alpha in alphas:\n",
    "    D_projections_standardized[alpha] = (D_projections[alpha] - np.mean(D_projections[alpha], axis=0)) / np.std(D_projections[alpha], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Σs = np.array([np.eye(200)] * 4)\n",
    "print(Σs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM():\n",
    "    def __init__(self, clusters = 40, max_iter = 100, random_starts = 10, tol = 1e-4):\n",
    "        \"\"\"\n",
    "        Initialize GMM with number of clusters, max iterations and random starts.\n",
    "        :param clusters: The number of clusters.\n",
    "        :param max_iter: The maximum number of iterations.\n",
    "        :param random_starts: The number of random starts.\n",
    "        :param tol: The tolerance for convergence.\n",
    "        \"\"\"\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.clusters = clusters\n",
    "        self.random_starts = random_starts\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the GMM to the data.\n",
    "        :param X: The data matrix.\n",
    "        \"\"\"\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        self.πs = np.ones(self.clusters) / self.clusters\n",
    "        self.Σs = np.array([np.eye(self.n_features)] * self.clusters)\n",
    "        \n",
    "        # best random start\n",
    "        best_ll = -np.inf\n",
    "        best_μs = None\n",
    "        best_Σs = None\n",
    "        best_πs = None\n",
    "\n",
    "        for _ in range(self.random_starts):\n",
    "            \n",
    "            # initialize means randomly\n",
    "            self.μs = np.random.randn(self.clusters, self.n_features)\n",
    "\n",
    "            ll = 0 # log likelihood\n",
    "            \n",
    "            for _ in range(self.max_iter):\n",
    "                # E-step\n",
    "                rs = self.e_step(X)\n",
    "\n",
    "                # M-step\n",
    "                self.m_step(X, rs)\n",
    "\n",
    "                # calculate the new log likelihood\n",
    "                nll = np.sum(np.log(np.sum(rs, axis=1) + 1e-10)) # to avoid log(0)\n",
    "                if abs(nll - ll) < self.tol:\n",
    "                    break\n",
    "\n",
    "                ll = nll\n",
    "\n",
    "            if ll > best_ll:\n",
    "                best_ll = ll\n",
    "                best_μs = self.μs.copy()\n",
    "                best_Σs = self.Σs.copy()\n",
    "                best_πs = self.πs.copy()\n",
    "\n",
    "\n",
    "        # set the best parameters\n",
    "        self.μs = best_μs\n",
    "        self.Σs = best_Σs\n",
    "        self.πs = best_πs\n",
    "\n",
    "        print(\"Model fitted successfully.\")\n",
    "\n",
    "    def e_step(self, X):\n",
    "        \"\"\"\n",
    "        E-step of the EM algorithm.\n",
    "        :param X: The data matrix.\n",
    "        :return: The responsibilities.\n",
    "        \"\"\"\n",
    "        rs = np.zeros((self.n_samples, self.clusters))\n",
    "\n",
    "        # calculate responsibilities\n",
    "        for k in range(self.clusters):\n",
    "            rs[:, k] = self.πs[k] * self.multivariate_gaussian(X, self.μs[k], self.Σs[k])\n",
    "\n",
    "        # normalize responsibilities\n",
    "        rs /= rs.sum(axis=1, keepdims=True) + 1e-10 # to avoid division by zero\n",
    "\n",
    "        return rs\n",
    "\n",
    "    def m_step(self, X, rs):\n",
    "        \"\"\"\n",
    "        M-step of the EM algorithm.\n",
    "        :param X: The data matrix.\n",
    "        :param rs: The responsibilities.\n",
    "        \"\"\"\n",
    "\n",
    "        #print shapes\n",
    "\n",
    "        # calculate sum of responsibilities per cluster\n",
    "        Nk = rs.sum(axis=0)\n",
    "        # update weights of clusters\n",
    "        self.πs = Nk / self.n_samples\n",
    "        # update means of clusters\n",
    "        self.μs = rs.T @ X / Nk[:, np.newaxis]\n",
    "\n",
    "        # print(f\"X shape: {X.shape}\")\n",
    "        # print(f\"rs shape: {rs.shape}\")\n",
    "        # print(f\"πs shape: {self.πs.shape}\")\n",
    "        # print(f\"μs shape: {self.μs.shape}\")\n",
    "        # print(f\"Σs shape: {self.Σs.shape}\")\n",
    "        # print(f\"Nk shape: {Nk.shape}\")\n",
    "\n",
    "        # update covariance matrices of clusters\n",
    "        self.Σs = np.zeros((self.clusters, self.n_features, self.n_features))\n",
    "        for k in range(self.clusters):\n",
    "            diff = X - self.μs[k]\n",
    "            self.Σs[k] = (rs[:, k][:, np.newaxis] * diff).T @ diff / Nk[k]\n",
    "\n",
    "    def multivariate_gaussian(self, X, μ, Σ):\n",
    "        \"\"\"\n",
    "        Multivariate Gaussian distribution.\n",
    "        :param X: The data matrix.\n",
    "        :param μ: The mean vector.\n",
    "        :param Σ: The covariance matrix.\n",
    "        :return: The pdf.\n",
    "        \"\"\"\n",
    "        d = X.shape[1]\n",
    "        det_Σ = np.linalg.det(Σ)\n",
    "        \n",
    "        first_term = 1 / ((2 * np.pi) ** (d / 2) * np.sqrt(det_Σ))\n",
    "        \n",
    "        pdfs = np.zeros(X.shape[0], dtype=float)\n",
    "\n",
    "        Σ_inv = np.linalg.inv(Σ)\n",
    "        for i in range(X.shape[0]):\n",
    "            diff = (X[i] - μ)[:, np.newaxis]\n",
    "            second_term = np.exp(-0.5 * diff.T @ Σ_inv @ diff)\n",
    "            print(diff.T @ Σ_inv @ diff)\n",
    "            pdfs[i] = first_term * second_term\n",
    "\n",
    "        return pdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(clusters=40, max_iter=100, random_starts=10, tol=1e-4)\n",
    "gmm.fit(D_projections[0.85])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
