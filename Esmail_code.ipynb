{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        num_cols = int(data[3:5])\n",
    "        num_rows = int(data[6:9])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=14)\n",
    "        return np.array(parsed).reshape(num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visaulize images of id = 6\n",
    "id = 5\n",
    "plt.figure(figsize=(8,8))\n",
    "for j in range(10):\n",
    "    img = read_image_file(f\"faces/s{id+1}/{j+1}.pgm\")\n",
    "    plt.subplot(5,5,(j+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visaulize images 1 of all ids \n",
    "j = 0\n",
    "plt.figure(figsize=(40,40))\n",
    "for id in range(40):\n",
    "    img = read_image_file(f\"faces/s{id+1}/{j+1}.pgm\")\n",
    "    plt.subplot(10,10,id+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating Data Matrix\n",
    "D = np.array([0]*92*112, dtype=int) # int or float ??\n",
    "y = np.array([], dtype=int)\n",
    "\n",
    "for i in range(40):\n",
    "    for j in range(10):\n",
    "        img = read_image_file(f\"faces/s{i+1}/{j+1}.pgm\")\n",
    "        img = img.reshape(-1)\n",
    "        D = np.vstack((D, img))\n",
    "        y = np.append(y,i+1)\n",
    "D = np.delete(D, 0, axis=0)\n",
    "\n",
    "# shape of Data Matrix and label vector\n",
    "print(D.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into training and testing sets\n",
    "odd_rows = np.array([i % 2 != 0 for i in range(400)]) \n",
    "\n",
    "# odds rows for taining set\n",
    "D_train = D[odd_rows]\n",
    "y_train = y[odd_rows]\n",
    "\n",
    "# even rows for testing set\n",
    "D_test = D[~ odd_rows]\n",
    "y_test = y[~ odd_rows]\n",
    "\n",
    "# shapes of resulting dataset\n",
    "print(D_train.shape, y_train.shape)\n",
    "print(D_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA():\n",
    "    def __init__(self, alpha=0.85):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def set_alpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def project(self, D, eigen_values=None,eigen_vectors=None):\n",
    "        # center the data matrix\n",
    "        D = D - np.mean(D, axis=0)\n",
    "\n",
    "        if eigen_values is None or eigen_vectors is None:\n",
    "            # get sorted eigen values, vectors of cov_mat(D) \n",
    "            eigen_values, eigen_vectors = self.get_sorted_eig(D)\n",
    "        \n",
    "        # count PCs from aplha\n",
    "        num_components = self.count_num_components(eigen_values)\n",
    "\n",
    "        # get projection matrix with num_components\n",
    "        projection_mat = eigen_vectors[:,:num_components]\n",
    "        # compute projected data\n",
    "        return D @ projection_mat\n",
    "\n",
    "    def get_sorted_eig(self, D):\n",
    "        # center the data matrix and get cov matrix\n",
    "        D = D - np.mean(D, axis=0)\n",
    "        cov_mat = np.cov(D, bias=True, rowvar=False)\n",
    "\n",
    "        eigen_values, eigen_vectors = np.linalg.eigh(cov_mat) \n",
    "\n",
    "        sort_indices = np.flip(np.argsort(eigen_values))\n",
    "\n",
    "        eigen_values = np.sort(eigen_values)[::-1]\n",
    "        eigen_vectors = eigen_vectors[:, sort_indices] \n",
    "        \n",
    "        return eigen_values, eigen_vectors\n",
    "\n",
    "    def count_num_components(self, eigen_values, alpha=None):\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "            \n",
    "        n = 1\n",
    "        total_variance = np.sum(eigen_values)\n",
    "        sum = 0\n",
    "        for i in range(len(eigen_values)):\n",
    "            sum = sum + eigen_values[i]\n",
    "            var_explained =  sum / total_variance\n",
    "            if var_explained >= alpha:\n",
    "                break\n",
    "            n = n + 1\n",
    "\n",
    "        return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute eigen values and eigen vectors of trained data\n",
    "pca = PCA()\n",
    "eigen_values, eigen_vectors = pca.get_sorted_eig(D_train)\n",
    "\n",
    "# save eigen values and eigen vectors\n",
    "np.save(\"train_eigen_val\", eigen_values)\n",
    "np.save(\"train_eigen_vec\", eigen_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eigen values and eigen vectors of trained data \n",
    "eigen_values = np.load(\"train_eigen_val.npy\")\n",
    "eigen_vectors = np.load(\"train_eigen_vec.npy\")\n",
    "\n",
    "# PCA with different aplhas\n",
    "alphas = [.8, .85, .9, .95]\n",
    "# D_projections {alpha: projected_data} \n",
    "D_projections = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    pca.set_alpha(alpha)\n",
    "    pca.count_num_components(eigen_values)\n",
    "    D_projections[alpha] = pca.project(D_train, eigen_values, eigen_vectors)\n",
    "    print(f\"Dimensions at alpha= {alpha} : {D_projections[alpha].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct images of some samples with different number of components\n",
    "sample_faces = [0, 5]\n",
    "num_components = [pca.count_num_components(eigen_values, alpha) for alpha in alphas]\n",
    "\n",
    "reconstruct_images = {}\n",
    "j = 0\n",
    "for  k in sample_faces:\n",
    "    for i in num_components:\n",
    "        img = D_train[k] @ (eigen_vectors[:,:i] @ eigen_vectors[:,:i].T) + np.mean(D_train, axis=0)\n",
    "        reconstruct_images[(k,i)] = img\n",
    "        j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visaulize reconstucted faces in PCA space\n",
    "plt.figure(figsize=(8,8))\n",
    "j = 1\n",
    "for key, img in reconstruct_images.items():\n",
    "        plt.subplot(4,4,j)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"sample face {key[0]+1}\\n{key[1]} components\",fontsize=10)\n",
    "        plt.imshow(img.reshape(112,92), cmap='gray')\n",
    "        j = j + 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visaulize Eigenfaces\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    img = eigen_vectors[:,i]\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Eigen value {i+1}\")\n",
    "    plt.imshow(img.reshape(112,92), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "class KMeans():\n",
    "    def __init__(self, K, rand_start=20):\n",
    "        self.K = K\n",
    "        self.rand_start = rand_start\n",
    "    \n",
    "    def setK(self, K):\n",
    "        self.K = K\n",
    "\n",
    "    def fit(self, D, y):\n",
    "        r_best = np.array([])\n",
    "        min_inertia = np.inf\n",
    "\n",
    "        # apply kmeans (rand_start) times\n",
    "        for i in range(self.rand_start):\n",
    "            # set K random centeriods: centers (K, # features)\n",
    "            centers = np.random.rand(self.K, D.shape[1]) * np.random.randint(np.max(D))\n",
    "\n",
    "            # intialize responsibility matrix(1-hot encode) with zeroes: r (# samples, k)\n",
    "            r = np.zeros((D.shape[0], self.K), dtype=bool)\n",
    "            \n",
    "            r, centers = self.kmeans_loop(D, r, centers)\n",
    "\n",
    "            # evaluate best cluster using interia\n",
    "            err = self.inertia(D, r, centers)\n",
    "            if  err < min_inertia:\n",
    "                r_best = r\n",
    "                min_inertia = err\n",
    "        \n",
    "        return r_best\n",
    "        \n",
    "    def kmeans_loop(self, D, r, centers):\n",
    "        r_prev = r.copy()\n",
    "\n",
    "        while True:\n",
    "            # compute Distance matrix for each data point x=D[i] with each center\n",
    "            # assign cluster for each data point\n",
    "            for i in range(len(D)):\n",
    "                cluster = np.argmin(np.linalg.norm(centers - D[i], axis=1))\n",
    "                r[i] = [j == cluster for j in range(self.K)]\n",
    "\n",
    "            # test for convergence\n",
    "            if np.array_equal(r_prev, r):\n",
    "                break\n",
    "            else:\n",
    "                r_prev = r.copy()\n",
    "            \n",
    "            # refitting center of each cluster\n",
    "            for j in range(self.K):\n",
    "                centers[j] = np.mean(D[r[:,j]], axis=0)\n",
    "        \n",
    "        return r, centers\n",
    "    \n",
    "    def inertia(self, D, r, centers):\n",
    "        # sum of Euclidean dist from each point to its cluster\n",
    "        sum = 0\n",
    "        for j in range(self.K):\n",
    "            cluster_dis = np.linalg.norm(D[r[:,j]] - centers[j], axis=1)\n",
    "            sum = sum + np.sum(cluster_dis)\n",
    "\n",
    "        return sum\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
